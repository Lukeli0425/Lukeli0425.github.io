<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Coord-SoS-PACT</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://lukeli0425.github.io/images/Coord-SoS-PACT.jpg">
    <meta property="og:image:type" content="image/png">
    <!-- <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840"> -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://lukeli0425.github.io/Coord-SoS-PACT/" />
    <meta property="og:title"
        content="Coordinate-based Speed of Sound Recovery for Aberration-Corrected Photoacoustic Computed Tomography" />
    <meta property="og:description"
        content="Photoacoustic computed tomography (PACT) is a non-invasive imaging modality, similar to ultrasound, with wide-ranging medical applications. Conventional PACT images are degraded by wavefront distortion caused by the heterogeneous speed of sound (SOS) in tissue. Accounting for these effects can improve image quality and provide medically useful information, but measuring the SOS directly is burdensome and the existing joint reconstruction method is computationally expensive. Traditional supervised learning techniques are currently inaccessible in this data-starved domain. In this work, we introduce an efficient, self-supervised joint reconstruction method that recovers SOS and high-quality images for ring array PACT systems. To solve this semi-blind inverse problem, we parametrize the SOS using either a pixel grid or a neural field (NF) and update it directly by backpropagating the gradients through a differentiable imaging forward model. Our method removes SOS aberrations more accurately and 35x faster than the current SOTA. We demonstrate the success of our method quantitatively in simulation and qualitatively on experimentally-collected and in vivo data.Our code and synthetic numerical phantoms are available on our project page: https://lukeli0425.github.io/Coord-SoS-PACT/." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title"
        content="Coordinate-based Speed of Sound Recovery for Aberration-Corrected Photoacoustic Computed Tomography" />
    <meta name="twitter:description"
        content="Photoacoustic computed tomography (PACT) is a non-invasive imaging modality, similar to ultrasound, with wide-ranging medical applications. Conventional PACT images are degraded by wavefront distortion caused by the heterogeneous speed of sound (SOS) in tissue. Accounting for these effects can improve image quality and provide medically useful information, but measuring the SOS directly is burdensome and the existing joint reconstruction method is computationally expensive. Traditional supervised learning techniques are currently inaccessible in this data-starved domain. In this work, we introduce an efficient, self-supervised joint reconstruction method that recovers SOS and high-quality images for ring array PACT systems. To solve this semi-blind inverse problem, we parametrize the SOS using either a pixel grid or a neural field (NF) and update it directly by backpropagating the gradients through a differentiable imaging forward model. Our method removes SOS aberrations more accurately and 35x faster than the current SOTA. We demonstrate the success of our method quantitatively in simulation and qualitatively on experimentally-collected and in vivo data.Our code and synthetic numerical phantoms are available on our project page: https://lukeli0425.github.io/Coord-SoS-PACT/." />
    <meta name="twitter:image" content="https://lukeli0425.github.io/images/Coord-SoS-PACT.jpg" />


    <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üí´</text></svg>"> -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script> -->

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Coordinate-based Speed of Sound Recovery for Aberration-Corrected<br>Photoacoustic Computed Tomography
                <br>
                <small>
                    <em>IEEE/CVF International Conference on Computer Vision (ICCV), 2025</em>
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://lukeli0425.github.io/">
                            <b>Tianao Li</b>
                        </a>
                        <br>Northwestern University
                    </li>
                    <li>
                        <a href="">
                            <b>Manxiu Cui</b>
                        </a>
                        <br>California Institute of Technology
                    </li>
                    <li>
                        <a href="https://rachmaninov-ma.wixsite.com/mysite/">
                            <b>Cheng Ma</b>
                        </a>
                        <br>Tsinghua University
                    </li>
                    <li>
                        <a href="https://www.alexander.vision/emma">
                            <b>Emma Alexander</b>
                        </a>
                        <br>Northwestern University
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="">
                            <!-- <img src="images/CVF.jpeg" height="60px"> -->
                            <img src="images/ICCV2025.png" height="70px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://arxiv.org/abs/2409.10876">
                            <img src="images/arxiv.jpg" height="60px">
                            <h4><strong>arXiv</strong></h4>
                        </a>
                    </li>
                    <!-- <li>
                        <a href="">
                        <img src="images/YouTube.png" height="60px">
                            <h4><strong>Video</strong></h4>
                        </a>
                    </li> -->
                    <li>
                        <a href="">
                        <img src="images/Google-Drive.png" height="60px">
                            <h4><strong>Dataset</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/Lukeli0425/Coord-SOS-PACT">
                            <img src="images/github.png" height="60px">
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- Slideshow container -->
                <div class="slideshow-container">
                    <!-- Full-width images with number and caption text -->
                    <div class="mySlides">
                        <div class="numbertext">1 / 3</div>
                        <video width="100%" muted autoplay loop controls>
                            <source src="images/nf_numerical_phantom.mp4" type="video/mp4">
                        </video>
                        <div class="text">Numerical Phantom</div>
                    </div>

                    <div class="mySlides">
                        <div class="numbertext">2 / 3</div>
                        <video width="100%" muted autoplay loop controls>
                            <source src="images/nf_leaf_phantom.mp4" type="video/mp4">
                        </video>
                        <div class="text">Leaf Phantom</div>
                    </div>

                    <div class="mySlides">
                        <div class="numbertext">3 / 3</div>
                        <video width="100%" muted autoplay loop controls>
                            <source src="images/nf_in_vivo_mouse_liver.mp4" type="video/mp4">
                        </video>
                        <div class="text"><em>In vivo Mouse Liver</em></div>
                    </div>

                    <!-- Next and previous buttons -->
                    <a class="prev" onclick="plusSlides(-1)">&#10094;</a>
                    <a class="next" onclick="plusSlides(1)">&#10095;</a>
                </div>
                <br>

                <!-- The dots/circles -->
                <div style="text-align:center">
                    <span class="dot" onclick="currentSlide(1)"></span>
                    <span class="dot" onclick="currentSlide(2)"></span>
                    <span class="dot" onclick="currentSlide(3)"></span>
                </div>

                <script type="text/javascript">
                    let slideIndex = 1;
                    showSlides(slideIndex);

                    // Next/previous controls
                    function plusSlides(n) {
                        showSlides(slideIndex += n);
                    }

                    // Thumbnail image controls
                    function currentSlide(n) {
                        showSlides(slideIndex = n);
                    }

                    function showSlides(n) {
                        let i;
                        let slides = document.getElementsByClassName("mySlides");
                        let dots = document.getElementsByClassName("dot");
                        if (n > slides.length) { slideIndex = 1 }
                        if (n < 1) { slideIndex = slides.length }
                        for (i = 0; i < slides.length; i++) {
                            slides[i].style.display = "none";
                        }
                        for (i = 0; i < dots.length; i++) {
                            dots[i].className = dots[i].className.replace(" active", "");
                        }
                        slides[slideIndex - 1].style.display = "block";
                        dots[slideIndex - 1].className += " active";
                    }
                </script>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Photoacoustic computed tomography (PACT) is a non-invasive imaging modality, similar to ultrasound, with wide-ranging medical applications. 
                    Conventional PACT images are degraded by wavefront distortion caused by the heterogeneous speed of sound (SOS) in tissue. 
                    Accounting for these effects can improve image quality and provide medically useful information, but measuring the SOS directly is burdensome and the existing joint reconstruction method is computationally expensive. 
                    Traditional supervised learning techniques are currently inaccessible in this data-starved domain.
                    In this work, we introduce an efficient, self-supervised joint reconstruction method that recovers SOS and high-quality images for ring array PACT systems. 
                    To solve this semi-blind inverse problem, we parametrize the SOS using either a pixel grid or a neural field (NF) and update it directly by backpropagating the gradients through a differentiable imaging forward model. 
                    Our method removes SOS aberrations more accurately and 35x faster than the current SOTA. 
                    We demonstrate the success of our method quantitatively in simulation and qualitatively on experimentally-collected and in vivo data. 
                </p>
            </div>
        </div>

        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="images/overview.png">
                </td>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <b>Figure 1. Self-Supervised Speed of Sound Recovery Corrects PACT Aberrations.</b>
                    (a) Backprojection converts photoacoustic measurements into images (purple), which suffer aberrations caused by unaccounted-for variation in the speed of sound (SOS) of tissue. 
                    Our method produces high-quality images through a self-supervised recovery of SOS. 
                    We begin with a stack of aberrated reconstructions, created with a varying delay parameter (green), roughly analogous to a focal stack. 
                    Each image patch is recovered with a multi-channel deconvolution.
                    Our forward model (dashed red) uses a trainable coordinate-based SOS representation to estimate the point spread functions (PSFs) at each location (white ‚Äúx‚Äù for example shown). 
                    The physics-based forward model and multichannel inversion are fully differentiable, enabling test-time training without any external training data, which is currently limited for this imaging modality. 
                    (b) We benchmark our method using both a neural field (NF) and pixel grid (PG) for SOS representation. 
                    Compared to the best existing methods, both with and without SOS recovery, we provide state-of-the-art image quality, and recover SOS with an order-of-magnitude speed-up.
                </p>
            </div>
        </div>

        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="images/figure_numerical.png">
                </td>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <b>Figure 4. Numerical simulation demonstrates accuracy and computational efficiency.</b>
                    (a) Our numerical phantom allows quantitative evaluation of image reconstruction under different SOS distributions in simulation. 
                    The PA signals are generated with k-wave simulation [31] using the IP and SOS shown. 
                    (b) The wavefront (sampled location marked by white ‚Äúx‚Äù in a) reconstructed by our method with NF (purple) and PG (green) is much closer to the true wavefront (red) than other methods, better capturing image aberrations. 
                    (c) We compare our method with conventional DAS, Dual-SOS DAS, our multi-channel deconvolution with the true SOS, and APACT. 
                    While conventional DAS assumes a uniform SOS and results in significant image aberrations, Dual-SOS DAS provides better contrast by assuming a single-body SOS but cannot fully undo the aberrations and reconstruct the SOS. 
                    Given an accurate SOS, our multi-channel deconvolution is able to efficiently reconstruct a high-quality IP image. 
                    APACT is able to deblur the image effectively but does not address overall shrinkage (see vertical shift in green boxes) and cannot reconstruct an accurate SOS. 
                    Our method with NF solves the shrinking problem by fully characterizing the wavefront and is able to fully reconstruct the IP and SOS (see metrics) in a much shorter time than APACT. 
                    Ours with PG also produces good IP images but generates stripe-like artifacts in the SOS that originate from the path-integral nature of the wavefront computation. 
                    Providing our method with the ground truth SOS leads to only marginal improvements in image quality. 
                    See visualizations of the convergence in the supplementary videos.
                </p>
            </div>
        </div>

        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="./images/figure_phantom.png">
                </td>
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="./images/figure_invivo.png">
                </td>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <b>Figure 5. Real-world results.</b>
                    We compare our methods to conventional DAS, Dual SOS DAS, and APACT on experimentally collected data, for which the true IP and SOS are unknown. 
                    Panel (a) shows a 3-SOS leaf-and-gel phantom [5] (see labeled photograph). 
                    Prior methods fail to capture the vein structure accurately, while our method succeeds in both simple regions (blue) as well as more challenging regions (red) featuring dim illumination and a material boundary. 
                    Our SOS map approximately recovers the material change in the phantom (white dotted line). 
                    Panel (b) shows the reconstructed images from in vivo mouse liver data from [3]. 
                    Despite requiring less computational time, our method precisely locates features like bright blood vessels and body edges (green) and effectively recovers fine structures with high contrast (blue and red). 
                    Notably, the SOS map reconstructed by our method with NF exhibits a superior match to the liver's anatomical shape compared to APACT (see Fig. S2 in supplement for overlaid SOS and IP). 
                    In both experiments, our method with PG produces artifacts in the SOS despite constrained by a strong TV regularization. 
                    See supplementary videos for visualizations of convergence.
                </p>
            </div>
        </div>

        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="images/figure_overlay.png">
                </td>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    <b>Figure S2. Overlaid initial pressure image and SOS of in vivo mouse liver.</b>
                    Our reconstructed SOS with NF (right) shows a superior match to the liver's anatomical shape in the initial pressure image.
                </p>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video (Currently Unavailable)
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <pre>@article{li2025coordinate,
    title={Coordinate-based Speed of Sound Recovery for Aberration-Corrected Photoacoustic Computed Tomography},
    author={Li, Tianao and Cui, Manxiu and Ma, Cheng and Alexander, Emma},
    journal={arXiv preprint arXiv:2409.10876},
    year={2025}
}
</pre>
                <!-- </textarea></center>
                </div> -->
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Press Release
                </h3>
                <p class="text-justify">
                    Read about this work on <a href="https://news.northwestern.edu/stories/2023/03/ai-algorithm-unblurs-the-cosmos">Northwestern Now</a>, <a href="https://www.popsci.com/technology/ai-algorithm-space-telescope/">Popular Science</a>, <a href="https://www.theregister.com/2023/04/03/ai_astronomy_telescope/">The Register</a>, and <a href="https://www.innovationnewsnetwork.com/computer-vision-algorithm-adapted-unblur-astronomical-images/31406/">Innovation News</a>.
                </p>
            </div>
        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    We gratefully acknowledge the support of the <a href="https://skai-institute.org">NSF-Simons AI-Institute for the Sky (SkAI)</a> via grants NSF AST-2421845 and Simons Foundation MPS-AI-00010513.
                    We would also like to thank Liujie Gu and Yan Luo for helping us with the numerical simulations.
                </p>
                <p style="text-align:right;">
                    Website template from <a href="http://mgharbi.com/">Micha√´l Gharbi</a>.
                </p>
            </div>
        </div>
    </div>

    <p>
        <center>
            <div id="clustrmaps-widget" style="width:6%">
                <script type="text/javascript" id="clstr_globe"
                    src="//clustrmaps.com/globe.js?d=LX-XU5v2AyHvdAz7Ic3cWsBeguE789rOYyRa8FFlsXk"></script>
            </div>
            <br>
            &copy; Tianao Li | Last update: Jul. 20, 2025
        </center>
    </p>

</body>

</html>