<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Course Projects</title>
    
    <meta name="author" content="Tianao Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="stylesheet" type="text/css" href=".stylesheet.css">
    <!-- <link rel="shortcut icon" src="images/icon_thu.png"> -->
    <!-- <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" /> -->

</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Course Projects</name>
                </p>
                
              </td>
            </tr>
          </tbody></table>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <!-- <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>WebGL-</b></papertitle>
                <br>
                <em>CS 351: Introduction to Computer Graphics, Northwestern University, Winter 2024</em>
                <br>
                <a href=""><b>[Code]</b></a>
                <br>
                <p></p>
              </td>
            </tr> -->

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/Sag A*.jpeg" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>A Survey on Black Hole Image Reconstruction</b></papertitle>
                <br>
                <em>CS 496: AI for Science, Northwestern University, Spring 2024</em>
                <br>
                <a href="A_Survey_on_Black_Hole_Image_Reconstruction.pdf"><b>[Paper]</b></a>
                <br>
                <p>
                  The Event Horizon Telescope (EHT) collaboration's groundbreaking image of the M87 black hole ignited a new era in black hole imaging. This endeavor requires sophisticated image reconstruction algorithms that combine data from global telescopes. However, reconstructing black holes presents a unique challenge: it's an ill-posed inverse problem. Unlike conventional imaging, there are infinitely many possible solutions that fit the collected data. Traditionally, researchers address this by incorporating prior knowledge, which can be unreliable for groundbreaking discoveries like black holes. Additionally, quantifying the uncertainty in the reconstructed image is crucial for astronomers to assess its reliability. These two aspects, uncertainty quantification and dependence on explicit priors, represent the major hurdles in black hole imaging.
                  <br>
                  This survey explores recent advancements that address these challenges. We focus on methods that reconstruct black hole images with uncertainty without relying on explicit priors. We'll explore how these methods leverage generative models within a variational Bayesian framework to overcome the limitations of traditional approaches. We'll also delve into the limitations of these recent methods and propose promising avenues for future research.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/fire019_out.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Fire Detection</b></papertitle>
                <br>
                <em>Digital Image Processing, Tsinghua University, Spring 2022</em>
                <br>
                <a href="https://github.com/Lukeli0425/Fire-Detection"><b>[Code]</b></a>
                <br>
                <p>This is a non-deep learning fire detection pipeline inspired by <a href="https://ieeexplore.ieee.org/abstract/document/7314551">this paper</a>. Our pipeline comprises of three parts: color space classifier, color component classifier and texture classifier. Our model was trained and tested on the <a href="https://bitbucket.org/gbdi/bowfire-dataset/src/master/">BoWFire Dataset</a> and is able to detect fire from static images with an accuracy of 80%.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/4439-B-Result.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Exoplanet Transit Photometry for TESS Planetary Candidates TOI-4439.01 & TOI-5278.01</b></papertitle>
                <br>
                <em>Observational Astronomy, Tsinghua University, Spring 2022</em>
                <br>
                <a href="https://github.com/Lukeli0425/Exoplanet-Fit"><b>[Code]</b></a>
                <a href="Tianao Li - Exoplanet Transit Photometry for TESS Planetary Candidates TOI-4439.01 & TOI-5278.01.pdf"><b>[Paper]</b></a>
                <br>
                <p>The <a href="https://tess.mit.edu">Transiting Exoplanet Survey Satellite (TESS)</a> is an all-sky survey mission led by MIT and NASA in search of exoplanets. A certain number of planet candidates (PC) discovered by TESS are not actual transiting exoplanets, which are usually referred as "false positives", therefore follow-up ground-based photometry is performed for verifications. We conduct ground-based transit photometry on two planets candidates declared in TESS, TOI-5278.01 and TOI-4439.01 with an 80cm telescope at <a href="http://chjaa.bao.ac.cn/html/index.html">Xinglong Observatory</a>, P.R. China. Our data processing pipeline comprises of three parts: image reduction, aperture photometry and EXOFAST fit. For TOI-4439.01, our result is in accordance with TESS data, proving the exoplanet nature, while the EXOFAST fit did not converge for TOI-5278.01 due to low SNR of the light curve.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/M13.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle><b>Astro Image Processing</b></papertitle>
                  <br>
                  <em>Observational Astronomy, Tsinghua University, Spring 2022</em>
                  <br>
                  <a href="https://github.com/Lukeli0425/Astro-Image-Processing"><b>[Code & Data]</b></a>
                  <br>
                  <p>This repo contains my code and data for astronomical image reduction. The images were taken at Huairou, Beijing with a 25cm telescope of <a href="http://astro.tsinghua.edu.cn">DoA</a>. Targets include M13, M51, M3, etc.</p>
              </td>
          </tr>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/vasp_demo.png" alt="dise">
                  <img style="width:100%;max-width:100%" src="images/vasp_demo2.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Video-Audio Signal Processing</b></papertitle>
                <br>
                <em>Introduction to Auditory-visual Information System, Tsinghua University, Fall 2021</em>
                <br>
                <a href="https://github.com/Lukeli0425/VASP"><b>[Code]</b></a>
                <br>
                <p>Developed three algorithms that solve the following problems respectively:<br>
                1. Recognize faces from videos clips.<br>
                2. Recongizes voices from audios.<br>
                3. Given a video of three speakers speaking at the same time, separate the speeches from the three speakers.<br>
                This project is implemented in Python with the aid of <a href="https://github.com/ageitgey/face_recognition">Face Recognition</a>, <a href="https://github.com/resemble-ai/Resemblyzer">Resemblyzer</a> and <a href="https://github.com/speechbrain/speechbrain">Speechbrain</a>.</p>
              </td>
            </tr>

            <tr>
                <td style="padding:14px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="images/SBUX_2021_prediction.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle><b>Stock Forecast with GPR</b></papertitle>
                    <br>
                    <em>Stochastic Processes, Tsinghua University, Fall 2021</em>
                    <br>
                    <a href="https://github.com/Lukeli0425/Stock-Forecast-with-GPR"><b>[Code]</b></a>
                    <br>
                    <p>Built an algorithm using Guassian Process Regression to predict the stock prices from previous observations. This project is implemented with Python and <a href="https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn.gaussian_process#module-sklearn.gaussian_process">Scikit Learn<a>.</p>
                </td>
            </tr>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/ss_cover.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle><b>Video Editing Based on Rhythm Matching</b></papertitle>
                  <br>
                  <em>Signals and Systems, Tsinghua University, Spring 2021</em>
                  <br>
                  <a href="https://github.com/Lukeli0425/THUEE-SS-Project2021"><b>[Code]</b></a>
                  <a href="https://www.youtube.com/watch?v=O4NTpthB3ys"><b>[Video]</b></a>
                  <br>
                  <p>Developed an algorithm to create a video from a given set of video clips and a piece of background music to best match the clips' audio rhythm with the background music. This project is implemented with Matlab.</p>
              </td>
          </tr>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                  Website template from <a href="https://jonbarron.info/">Dr. Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        </td>
      </tr>
    </table>
   
    <p><center>
            <div id="clustrmaps-widget" style="width:6%">
              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=B3ZunPpD9-61O5IU9p52JBGozvYmus7V0VaVbYjY1g4"></script>
            </div>        
            <br>
            &copy; Tianao Li | Last update: Jul. 17, 2023
    </center></p>
  </body>
</html>
