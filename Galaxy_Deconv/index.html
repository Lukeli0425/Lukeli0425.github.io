
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Galaxy-Deconv</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <meta property="og:image" content="https://jonbarron.info/mipnerf360/img/gardenvase.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jonbarron.info/mipnerf360/"/>
    <meta property="og:title" content="Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields" />
    <meta property="og:description" content="Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on 'unbounded' scenes, where the camera may point in any direction and content may exist at any distance. In this setting, existing NeRF-like models often produce blurry or low-resolution renderings (due to the unbalanced detail and scale of nearby and distant objects), are slow to train, and may exhibit artifacts due to the inherent ambiguity of the task of reconstructing a large scene from a small set of images. We present an extension of mip-NeRF (a NeRF variant that addresses sampling and aliasing) that uses a non-linear scene parameterization, online distillation, and a novel distortion-based regularizer to overcome the challenges presented by unbounded scenes. Our model, which we dub 'mip-NeRF 360' as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 54% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields" />
    <meta name="twitter:description" content="Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on 'unbounded' scenes, where the camera may point in any direction and content may exist at any distance. In this setting, existing NeRF-like models often produce blurry or low-resolution renderings (due to the unbalanced detail and scale of nearby and distant objects), are slow to train, and may exhibit artifacts due to the inherent ambiguity of the task of reconstructing a large scene from a small set of images. We present an extension of mip-NeRF (a NeRF variant that addresses sampling and aliasing) that uses a non-linear scene parameterization, online distillation, and a novel distortion-based regularizer to overcome the challenges presented by unbounded scenes. Our model, which we dub 'mip-NeRF 360' as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 54% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes." />
    <meta name="twitter:image" content="https://jonbarron.info/mipnerf360/img/gardenvase.jpg" /> -->


    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’«</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Galaxy Image Deconvolution for Weak Gravitational Lensing <br> with Unrolled Plug-and-Play ADMM <br> 
                <small>
                    Monthly Notices of the Royal Astronomical Society: Letters
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://lukeli0425.github.io/">
                          <b>Tianao Li</b>
                        </a>
                        <br>Tsinghua University
                    </li>
                    <li>
                        <a href="https://www.alexander.vision/emma">
                            <b>Emma Alexander</b>
                        </a>
                        <br>Northwestern University
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://academic.oup.com/mnrasl/article/522/1/L31/7075894?login=false">
                            <image src="img/ras.jpg" height="65px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2211.01567">
                            <image src="img/arxiv.jpg" height="60px">
                                <h4><strong>arXiv</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="">
                            <image src="img/Youtube.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://drive.google.com/drive/folders/1IwgvbetMDpLK2skRalYWmth2J1gvF-qm">
                            <image src="img/Google-Drive.png" height="60px" width="">
                                <h4><strong>Dataset</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/Lukeli0425/Galaxy-Deconv">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/gardenvase_720.mp4" type="video/mp4" />
                </video> -->
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="./img/pipeline.jpg">
                </td>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-center">
                    <b>Figure 1. Overview of the image processing pipeline.</b>
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Removing optical and atmospheric blur from galaxy images significantly improves galaxy shape measurements for weak gravitational lensing and galaxy evolution studies. This ill-posed linear inverse problem is usually solved with deconvolution algorithms enhanced by regularisation priors or deep learning. We introduce a so-called "physics-informed deep learning" approach to the Point Spread Function (PSF) deconvolution problem in galaxy surveys. We apply algorithm unrolling and the Plug-and-Play technique to the Alternating Direction Method of Multipliers (ADMM), in which a neural network learns appropriate hyperparameters and denoising priors from simulated galaxy images. We characterise the time-performance trade-off of several methods for galaxies of differing brightness levels as well as our method's robustness to systematic PSF errors and ablations. We show an improvement in reduced shear ellipticity error of 38.6% (SNR=20)/45.0% (SNR=200) compared to classic methods and 7.4% (SNR=20)/33.2% (SNR=200) compared to modern methods.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/gardenvase_720.mp4" type="video/mp4" />
                </video> -->
                <td style="padding:2.5%;width:100%;max-width:100%">
                    <img style="width:100%;max-width:100%" src="./img/grid.jpg">
                </td>
            </div>
            <div class="col-md-8 col-md-offset-2">
                <p class="text-center">
                    <b>Figure 2. An illustration of performance at multiple SNR levels.</b>
                </p>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video (Currently Unavailable)
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->

            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <pre>
@article{li2023galaxy,
    title={Galaxy image deconvolution for weak gravitational lensing with unrolled plug-and-play ADMM},
    author={Li, Tianao and Alexander, Emma},
    journal={Monthly Notices of the Royal Astronomical Society: Letters},
    volume={522},
    number={1},
    pages={L31--L35},
    year={2023},
    publisher={Oxford University Press}
}</pre>
                    <!-- </textarea></center>
                </div> -->
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Press Release
                </h3>
                <p class="text-justify">
                    Read about this work on <a href="https://news.northwestern.edu/stories/2023/03/ai-algorithm-unblurs-the-cosmos">Northwestern Now</a>, <a href="https://www.mccormick.northwestern.edu/magazine/fall-2023/big-idea-ai-algorithm-unblurs-cosmos/">Northwestern Engineering Magazine</a>, <a href="https://www.popsci.com/technology/ai-algorithm-space-telescope/">Popular Science</a>, <a href="https://www.theregister.com/2023/04/03/ai_astronomy_telescope/">The Register</a>, and <a href="https://www.innovationnewsnetwork.com/computer-vision-algorithm-adapted-unblur-astronomical-images/31406/">Innovation News</a>.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    We would like to thank Adam Miller, Jason Wang, Keming Zhang, Nick Antipa, and an anonymous reviewer for their valuable advice, and the Computational Photography Lab (esp. Aniket Dashpute) at Northwestern University for support of computational resources.
                    <br>
                    This website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a>.
                </p>
            </div>
        </div>
    </div>

    <p><center>
        <div id="clustrmaps-widget" style="width:6%">
            <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=LpEvw03xSULsHwHzo4DISDyrZET_wOimBQ12H4SZPAY"></script>        </div>        
        <br>
        &copy; Tianao Li | Last update: Apr. 5, 2023
</center></p>

</body>
</html>

